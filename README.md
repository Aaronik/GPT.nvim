# LLM plugin for neovim

### * Supports Ollama, OpenAI

* Kills request process when window is closed
* OR Finishes requests safely in background!

## TODO

* Rename to something better than GPT. Models? TwoModel? Maybe GPT is good?
* Make a readme fr
* Error handling for ollama and openai providers
* Focus same buffer on nui exit?
* Prompt tests?
* Chat loading indicator?
* Add copilot support .. Very hard as it turns out
* Protect against opening windows many times?
* One really big integration flow for each window
