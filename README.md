# LLM plugin for neovim

### * Supports Ollama, OpenAI, and Copilot

* Kills request process when window is closed
* OR Finishes requests safely in background!

## TODO

* Focus same buffer on nui exit
* Loading indicators
* Code prompt
* add files to chat / code
* on q, save input
* Filetype automatically in code (and chat?)
* Make prompt tests
* Code window clears right pane upon new llm request
* Code window keeps input alive
* Code window has loading indicator
* Chat window has loading indicator
