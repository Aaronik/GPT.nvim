# LLM plugin for neovim

### * Supports Ollama, OpenAI, and Copilot

* Kills request process when window is closed
* OR Finishes requests safely in background!

## TODO

* Make a readme fr
* Error handling for ollama and openai providers
* Focus same buffer on nui exit
* Prompt tests
* Chat loading indicator
* Add copilot support
* Protect against opening windows many times?
* One really big integration flow for each window
