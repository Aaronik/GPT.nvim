# LLM plugin for neovim

### * Supports Ollama, OpenAI, and Copilot

* Kills request process when window is closed
* OR Finishes requests safely in background!

## TODO

* Focus same buffer on nui exit
* Code prompt
* add files to chat / code
* on q, save input
* Filetype automatically in code (and chat?)
* Make prompt tests
* Code window clears right pane upon new llm request
* Code window keeps input alive
* Chat window has loading indicator
* Let requests finish in background
* Go to gpt-4
* exiting the layout causes same behavior as q
* Handle graceful window resizing
